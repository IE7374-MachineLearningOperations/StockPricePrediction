{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac3c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6fa1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df89d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 6ms/step\n",
      "RMSE - LSTM: 11.137208872725754\n",
      "MAE - LSTM: 9.180786132812496\n",
      "MAPE - LSTM: 4.460068097216628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Function to build the LSTM model\n",
    "def build_lstm_model(X_train, units=50, dropout_rate=0.2, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    Builds and compiles the LSTM model based on input parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training data (used to get input shape)\n",
    "    - units: Number of LSTM units\n",
    "    - dropout_rate: Dropout rate to prevent overfitting\n",
    "    - optimizer: Optimizer to be used for model compilation\n",
    "    \n",
    "    Returns:\n",
    "    - model: Compiled LSTM model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))  # Output layer with 1 neuron (regression task)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(df, timesteps=10):\n",
    "    \"\"\"\n",
    "    Preprocesses the data, scaling features and reshaping into a format suitable for LSTM.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the features and target column ('close' in this case)\n",
    "    - timesteps: Number of previous days to use as input features\n",
    "    \n",
    "    Returns:\n",
    "    - X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled: Preprocessed and scaled data\n",
    "    \"\"\"\n",
    "    # Scaling the features and target\n",
    "    scaler = MinMaxScaler()\n",
    "    X = df.drop(['close'], axis=1)\n",
    "    y = df['close']\n",
    "    \n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "    \n",
    "    # Reshaping the data to fit LSTM input format\n",
    "    X_reshaped, y_reshaped = [], []\n",
    "    for i in range(timesteps, len(X_scaled)):\n",
    "        X_reshaped.append(X_scaled[i-timesteps:i])\n",
    "        y_reshaped.append(y_scaled[i])\n",
    "\n",
    "    X_reshaped, y_reshaped = np.array(X_reshaped), np.array(y_reshaped)\n",
    "\n",
    "    # Train-test split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# Function to train the LSTM model and calculate performance metrics\n",
    "def train_and_evaluate_lstm(df, timesteps=10, units=50, dropout_rate=0.2, optimizer='adam', batch_size=32, epochs=20):\n",
    "    \"\"\"\n",
    "    Trains the LSTM model, evaluates it, and returns error metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing features and target\n",
    "    - timesteps: Number of previous days to use as input features\n",
    "    - units: Number of units in the LSTM layer\n",
    "    - dropout_rate: Dropout rate for regularization\n",
    "    - optimizer: Optimizer to use for training\n",
    "    - batch_size: Batch size for training\n",
    "    - epochs: Number of epochs to train the model\n",
    "    \n",
    "    Returns:\n",
    "    - model: Trained LSTM model\n",
    "    - rmse: Root Mean Squared Error\n",
    "    - mae: Mean Absolute Error\n",
    "    - mape: Mean Absolute Percentage Error\n",
    "    \"\"\"\n",
    "    # Preprocess the data\n",
    "    X_train, X_test, y_train, y_test, scaler = preprocess_data(df, timesteps)\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = build_lstm_model(X_train, units=units, dropout_rate=dropout_rate, optimizer=optimizer)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform the predictions and true values\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "    y_test_orig = scaler.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate error metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "    mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "    mape = np.mean(np.abs((y_test_orig - y_pred) / y_test_orig)) * 100\n",
    "\n",
    "    print(\"RMSE - LSTM:\", rmse)\n",
    "    print(\"MAE - LSTM:\", mae)\n",
    "    print(\"MAPE - LSTM:\", mape)\n",
    "\n",
    "    return model, rmse, mae, mape\n",
    "\n",
    "# Example usage\n",
    "# Assuming df is your DataFrame containing the stock data with 'close' as the target column\n",
    "# df = ...  # Load your stock price dataset\n",
    "\n",
    "# Hyperparameters\n",
    "timesteps = 10\n",
    "units = 50\n",
    "dropout_rate = 0.2\n",
    "optimizer = 'adam'\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# Train and evaluate the model\n",
    "model, rmse, mae, mape = train_and_evaluate_lstm(df, timesteps, units, dropout_rate, optimizer, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee7a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install --upgrade keras\n",
    "#pip install --upgrade tensorflow\n",
    "#pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f582af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
