name: Model Training

on:
  push:
    branches:
      - main       # main branch for main setup and training

jobs:
  train_model:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      # Set up Python
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10.5'  

      # Install all dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Run Unit Tests before Model Training
      - name: Run Unit Tests
        run: |
          pytest tests/ --maxfail=1 --disable-warnings

      # Authenticate with GCP
      - name: Authenticate to GCP
        if: github.ref == 'refs/heads/main'  
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
        run: |
          echo "${GCP_SERVICE_ACCOUNT_KEY}" | base64 --decode > ${HOME}/gcp-key.json
          gcloud auth activate-service-account --key-file=${HOME}/gcp-key.json
          gcloud config set project ${GCP_PROJECT_ID}

      # Conditional Model Training: GCP for main branch, local for test branch
      - name: Trigger Model Training
        env:
          GCP_BUCKET_NAME: ${{ secrets.GCP_BUCKET_NAME }}
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            # Production Training on Google Cloud AI Platform
            gcloud ai-platform jobs submit training model_training_$(date +%Y%m%d_%H%M%S) \
              --region us-central1 \
              --module-name trainer.task \
              --package-path ./trainer \
              --python-version 3.12 \
              --runtime-version 2.5 \
              --job-dir gs://${GCP_BUCKET_NAME}/models/training_$(date +%Y%m%d_%H%M%S) \
              -- \
              --additional_training_args
          else
            # Test Training Locally for the test branch
            echo "Running model training locally for testing"
            python trainer/task.py --test_data ./data/test_data.csv
          fi

      # Trigger Airflow DAG after Successful Training (for Production)
      - name: Trigger Airflow DAG
        if: github.ref == 'refs/heads/main'
        env:
          AIRFLOW_URL: ${{ secrets.AIRFLOW_URL }}
          AIRFLOW_DAG_TRIGGER_TOKEN: ${{ secrets.AIRFLOW_DAG_TRIGGER_TOKEN }}
        run: |
          curl -X POST "${AIRFLOW_URL}/api/v1/dags/model_deployment_dag/dagRuns" \
          -H "Authorization: Bearer ${AIRFLOW_DAG_TRIGGER_TOKEN}" \
          -H "Content-Type: application/json" \
          -d '{"conf": {"job_id": "model_training_$(date +%Y%m%d_%H%M%S)", "bucket_name": "${GCP_BUCKET_NAME}"}}'

      # Save Training Logs as Artifacts
      - name: Upload Training Logs
        uses: actions/upload-artifact@v3
        with:
          name: training-logs
          path: logs/

      # Send notification on failure
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            github.issues.createComment({
              issue_number: context.issue.number,
              body: 'Model training failed on `${{ github.ref }}` branch. Please check logs for details.'
            })
