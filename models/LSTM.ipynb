{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac3c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6fa1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# Function to build the LSTM model\n",
    "def build_lstm_model(X_train, units=50, dropout_rate=0.2, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    Builds and compiles the LSTM model based on input parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training data (used to get input shape)\n",
    "    - units: Number of LSTM units\n",
    "    - dropout_rate: Dropout rate to prevent overfitting\n",
    "    - optimizer: Optimizer to be used for model compilation\n",
    "    \n",
    "    Returns:\n",
    "    - model: Compiled LSTM model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))  # Output layer with 1 neuron (regression task)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(df, timesteps=10):\n",
    "    \"\"\"\n",
    "    Preprocesses the data, scaling features and reshaping into a format suitable for LSTM.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the features and target column ('close' in this case)\n",
    "    - timesteps: Number of previous days to use as input features\n",
    "    \n",
    "    Returns:\n",
    "    - X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled: Preprocessed and scaled data\n",
    "    \"\"\"\n",
    "    # Scaling the features and target\n",
    "    scaler = MinMaxScaler()\n",
    "    X = df.drop(['close'], axis=1)\n",
    "    y = df['close']\n",
    "    \n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "    \n",
    "    # Reshaping the data to fit LSTM input format\n",
    "    X_reshaped, y_reshaped = [], []\n",
    "    for i in range(timesteps, len(X_scaled)):\n",
    "        X_reshaped.append(X_scaled[i-timesteps:i])\n",
    "        y_reshaped.append(y_scaled[i])\n",
    "\n",
    "    X_reshaped, y_reshaped = np.array(X_reshaped), np.array(y_reshaped)\n",
    "\n",
    "    # Train-test split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# Function to train the LSTM model and calculate performance metrics\n",
    "def train_and_evaluate_lstm(df, timesteps=10, units=50, dropout_rate=0.2, optimizer='adam', batch_size=32, epochs=20):\n",
    "    \"\"\"\n",
    "    Trains the LSTM model, evaluates it, and returns error metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing features and target\n",
    "    - timesteps: Number of previous days to use as input features\n",
    "    - units: Number of units in the LSTM layer\n",
    "    - dropout_rate: Dropout rate for regularization\n",
    "    - optimizer: Optimizer to use for training\n",
    "    - batch_size: Batch size for training\n",
    "    - epochs: Number of epochs to train the model\n",
    "    \n",
    "    Returns:\n",
    "    - model: Trained LSTM model\n",
    "    - rmse: Root Mean Squared Error\n",
    "    - mae: Mean Absolute Error\n",
    "    - mape: Mean Absolute Percentage Error\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test, scaler = preprocess_data(df, timesteps)\n",
    "    model = build_lstm_model(X_train, units=units, dropout_rate=dropout_rate, optimizer=optimizer)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "    y_test_orig = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "    mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "    mape = np.mean(np.abs((y_test_orig - y_pred) / y_test_orig)) * 100\n",
    "    \n",
    "    print(f\"RMSE: {rmse}, MAE: {mae}, MAPE: {mape}\")\n",
    "    \n",
    "    return model, history, X_test, y_test_orig, rmse, mae, mape\n",
    "\n",
    "\n",
    "\n",
    "def hyperparameter_sensitivity(df, param_ranges):\n",
    "    results = []\n",
    "    for param, values in param_ranges.items():\n",
    "        param_results = []\n",
    "        for value in values:\n",
    "            if param == 'units':\n",
    "                _, _, _, _, rmse, _, _ = train_and_evaluate_lstm(df, units=value)\n",
    "            elif param == 'dropout_rate':\n",
    "                _, _, _, _, rmse, _, _ = train_and_evaluate_lstm(df, dropout_rate=value)\n",
    "            elif param == 'optimizer':\n",
    "                _, _, _, _, rmse, _, _ = train_and_evaluate_lstm(df, optimizer=value)\n",
    "            param_results.append((value, rmse))\n",
    "        results.append((param, param_results))\n",
    "    \n",
    "    # Plot results\n",
    "    for param, param_results in results:\n",
    "        values, rmses = zip(*param_results)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(values, rmses, marker='o')\n",
    "        plt.title(f'Sensitivity Analysis: {param}')\n",
    "        plt.xlabel(param)\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.show()\n",
    "\n",
    "def feature_importance(model, X_test):\n",
    "    # Use SHAP for feature importance\n",
    "    explainer = shap.DeepExplainer(model, X_test[:100])\n",
    "    shap_values = explainer.shap_values(X_test[:100])\n",
    "    \n",
    "    # Plot feature importance\n",
    "    shap.summary_plot(shap_values[0], X_test[:100], plot_type=\"bar\")\n",
    "\n",
    "\n",
    "# Train and evaluate the model\n",
    "model, history, X_test, y_test, rmse, mae, mape = train_and_evaluate_lstm(df)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter sensitivity analysis\n",
    "param_ranges = {\n",
    "    'units': [30, 50, 70, 100],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3, 0.4],\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd']\n",
    "}\n",
    "hyperparameter_sensitivity(df, param_ranges)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee7a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install --upgrade keras\n",
    "#pip install --upgrade tensorflow\n",
    "#pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6e3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
